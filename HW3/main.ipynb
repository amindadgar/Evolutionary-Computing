{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolutionary Computing Exercise No. 3\n",
    "**Stu. Name:** Mohammad Amin Dadgar\n",
    "\n",
    "**Stu. Id:** 4003624016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representation\n",
    "Representation for our algorithm has three levels.\n",
    "\n",
    "- First level is just showing a concept for the network architecture in which the green boxes are optional (can be shown or not, 0 or 1)\n",
    "\n",
    "    <img src='architecture_level1.png'>\n",
    "- Second level is representing the transformer layer\n",
    "\n",
    "    <img src='architecture_level2.png'>\n",
    "- And the third level is showing the FFN and feed-forward network architectures\n",
    "\n",
    "    <img src='architecture_level3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each gene we can use numerical values which are 0 to 9. As we can see in the exercise each hyperparameter has 2, 3, or 4 values and by that we can convert the numerical values from intervals as below\n",
    "\n",
    "**Two valued hyperparameters:**\n",
    "- 0:4 → 0\n",
    "- 5:9 → 1\n",
    "\n",
    "**Three valued hyperparameters:**\n",
    "- 0:3 → 0\n",
    "- 4:6 → 1\n",
    "- 7:9 → 2\n",
    "\n",
    "**Four valued hyperparameters:**\n",
    "- 0:1 → 0\n",
    "- 2:4 → 1\n",
    "- 5:7 → 2\n",
    "- 8:9 → 3\n",
    "\n",
    "**100 valued hyperparameters:**\n",
    "- 0 → 0\n",
    "- 1 → 10\n",
    "- 2 → 20\n",
    "- ...\n",
    "- 9 → 90\n",
    "- And 100 would not really work in our 100 valued parametered dropout probability, so we'll exclude it from possible values. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to represent a chromsome `1+3×(3+3×2)+3` bits are requierd. The first `1` is $d_{model}$, then in the clause `3×(3+3×2)+3`, the first `3` is showing three possible transform layers. In the paranthesis the first `3` is showing the bit for attention head count and normalization layers then the `3` in multiplication is the count of possible hyperparameters in FFN layer (we could have 2 FFN layer in a transformer) and the last `3` in the equation is the final FFN layer for the network. So `31` bits will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recombination and Mutation\n",
    "To combine chromsomes for two recombination and mutation methods, we should assume the three level architecture for it. To that aim, We had implemented the mutation based on the conceptual (level 1) chromosome meaning the transformers and FFN layer are mutated as a pack. For recombination method, a normal single point or uniform cross-over can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End Condition\n",
    "The end condition is the count of generations, which is 10 as given in the exercise.\n",
    "### Fitness Function\n",
    "The fitness function is assumed the training 5 epoch of the transformer network and returning the 5 average test accuracy of it. As we will see the transfomer network does have high computational complexity (in time and hardware resources), so that's the reason that the end condition, averaging count, and epochs are set as low as they can be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from population import generate_population\n",
    "from combination import mutation_creep, single_point\n",
    "from util import convert_genotype_to_phenotype_values, map_hyperparameters\n",
    "from fitness import static_fitness\n",
    "from selection import binary_tournament\n",
    "from transformer_network_creator import fitness_evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,\n",
       " ((20, 'R', 0.2, True), (30, 'R', 0.4, True), 4),\n",
       " ((10, 'S', 0.5, False), (20, 'S', 0.9, True), 2),\n",
       " ((30, 'S', 0.7, False), (10, 'S', 0.7, True), 1),\n",
       " (20, 'S', 0.3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop = generate_population()\n",
    "convert_genotype_to_phenotype_values(pop[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_run(pop_count, SELECTION_METHOD, FITNESS_FUNCTION, MUTATION_METHOD, RECOMBINATION_METHOD, initial_population=None, initial_population_fitness = None, p_m=0.1, p_c =0.9, max_generations = 10, RESULTS_DIR='/content/gdrive/MyDrive/EC Project/'):\n",
    "    \"\"\"\n",
    "    one constraint should be always given as input, the maximum capacity or maximum distance\n",
    "    \"\"\"\n",
    "\n",
    "    ## if we had generated population before\n",
    "    if initial_population is None:\n",
    "      population = generate_population(pop_size=pop_count)\n",
    "      fitness_pop = []\n",
    "      for chromosome in population:\n",
    "          chromosome_fitness = FITNESS_FUNCTION(chromosome, None, 5)\n",
    "          fitness_pop.append(chromosome_fitness)\n",
    "    else:\n",
    "      print('Population is loaded from file!\\n')\n",
    "      fitness_pop = initial_population_fitness\n",
    "      population = initial_population\n",
    "    \n",
    "    best_chromosome = None\n",
    "    best_chromsome_fitness = None\n",
    "\n",
    "    for generation_idx in range(max_generations):\n",
    "        print(f'Generation Number: {generation_idx}')\n",
    "\n",
    "        # with open('result.txt', mode='a') as file:\n",
    "        #     file.write(f'\\nGeneration number: {generation_idx}\\n')\n",
    "\n",
    "\n",
    "        ## create pair of the parents\n",
    "        parent_pairs = []\n",
    "        for _ in range(pop_count):\n",
    "            pair = SELECTION_METHOD(population, fitness_pop)\n",
    "            parent_pairs.append(pair)\n",
    "\n",
    "        \n",
    "        offsprings = []\n",
    "        fitness_offsprings = []\n",
    "        for parents in parent_pairs:\n",
    "            recombination_p = np.random.random()\n",
    "\n",
    "            ## the offspring for this iteration\n",
    "            ## first save the parents to change them later\n",
    "            iteration_offspring = [parents[0], parents[1]]\n",
    "            \n",
    "            ######## Recombination ########\n",
    "            if recombination_p < p_c:\n",
    "                offspring1, offspring2 =  RECOMBINATION_METHOD(iteration_offspring[0], iteration_offspring[1])\n",
    "\n",
    "                iteration_offspring = [offspring1, offspring2]\n",
    "\n",
    "            ######## Mutation ########\n",
    "            offspring1 = MUTATION_METHOD(iteration_offspring[0], p_m)\n",
    "            offspring2 = MUTATION_METHOD(iteration_offspring[1], p_m)\n",
    "\n",
    "            iteration_offspring = [offspring1, offspring2]\n",
    "                \n",
    "            ## finally append the genarated offsprings to offspring array \n",
    "            offsprings.append(iteration_offspring[0])\n",
    "            offsprings.append(iteration_offspring[1])\n",
    "            \n",
    "            fitness_offsprings.append(FITNESS_FUNCTION(iteration_offspring[0], RESULTS_DIR + f'generation_number_{generation_idx}.txt', 5))\n",
    "            fitness_offsprings.append(FITNESS_FUNCTION(iteration_offspring[1], RESULTS_DIR + f'generation_number_{generation_idx}.txt', 5))\n",
    "            \n",
    "                \n",
    "        ######## Replacement ########\n",
    "\n",
    "        ## the whole generation: parents + offsprings\n",
    "        generation_population = population.copy()\n",
    "        generation_population.extend(offsprings)\n",
    "\n",
    "        ## whole generation fitness: parents fitness + offsprings fitness\n",
    "        generation_fitness = fitness_pop.copy()\n",
    "        generation_fitness.extend(fitness_offsprings)\n",
    "\n",
    "        ## the sorted generation\n",
    "        generation_population_sorted = np.array(generation_population)[np.argsort(generation_fitness)]\n",
    "        generation_fitness_sorted = np.sort(generation_fitness)\n",
    "\n",
    "        ## Step 10\n",
    "        ## extract the best of the new generation\n",
    "        best_of_generation_population = generation_population_sorted[:pop_count]\n",
    "        best_of_generation_fitness = generation_fitness_sorted[:pop_count]\n",
    "\n",
    "        best_chromosome = generation_population_sorted[0]\n",
    "        best_chromsome_fitness = generation_fitness_sorted[0]\n",
    "        \n",
    "        ## save them into the original population arrays\n",
    "        population = best_of_generation_population.tolist()\n",
    "        fitness_pop = best_of_generation_fitness.tolist()\n",
    "\n",
    "    \n",
    "    return best_chromosome, best_chromsome_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation Number: 0\n",
      "Generation Number: 1\n",
      "Generation Number: 2\n",
      "Generation Number: 3\n",
      "Generation Number: 4\n",
      "Generation Number: 5\n",
      "Generation Number: 6\n",
      "Generation Number: 7\n",
      "Generation Number: 8\n",
      "Generation Number: 9\n"
     ]
    }
   ],
   "source": [
    "## starting the algorithm with a static fitness value\n",
    "## the algorithm will run randomly, but we want to debug any problems if it has\n",
    "answer_chromosome, answer_chromsome_fitness = algorithm_run(pop_count=10, \n",
    "                SELECTION_METHOD=binary_tournament, \n",
    "                FITNESS_FUNCTION=static_fitness, \n",
    "                MUTATION_METHOD=mutation_creep, \n",
    "                RECOMBINATION_METHOD=single_point,\n",
    "                p_m=0.1,\n",
    "                p_c=0.9,\n",
    "                max_generations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,\n",
       " ((20, 'S', 0.5, True), (20, 'R', 0.7, True), 2),\n",
       " ((10, 'S', 0.9, False), (5, 'S', 0.7, True), 8),\n",
       " ((5, 'R', 0.3, True), (20, 'S', 0.5, True), 1),\n",
       " (10, 'R', 0))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_genotype_to_phenotype_values(pop[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4577566333000000000000000000000'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CH = mutation_creep(pop[0], 1)\n",
    "CH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,\n",
       " ((20, 'S', 0.7, False), (20, 'S', 0.3, True), 2),\n",
       " ((None, None, None, None), (None, None, None, True), 1),\n",
       " ((None, None, None, None), (None, None, None, True), 1),\n",
       " (None, None, None))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_genotype_to_phenotype_values(CH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformer_network_creator\u001b[39;00m \u001b[39mimport\u001b[39;00m start_training\n\u001b[1;32m----> 3\u001b[0m start_training(answer_chromosome)\n",
      "File \u001b[1;32md:\\lessons\\MSc\\3rd Term\\Evolutionary Computing\\Exercise\\Github repo\\Evolutionary-Computing\\HW3\\transformer_network_creator.py:171\u001b[0m, in \u001b[0;36mstart_training\u001b[1;34m(phenotype_chromosome)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstart_training\u001b[39m(phenotype_chromosome):\n\u001b[1;32m--> 171\u001b[0m     model \u001b[39m=\u001b[39m create_model(phenotype_chromosome)\n\u001b[0;32m    172\u001b[0m     x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m load_data()\n\u001b[0;32m    174\u001b[0m     model\u001b[39m.\u001b[39mfit(x_train, y_train, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n",
      "File \u001b[1;32md:\\lessons\\MSc\\3rd Term\\Evolutionary Computing\\Exercise\\Github repo\\Evolutionary-Computing\\HW3\\transformer_network_creator.py:151\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m(phenotype_chromosome, maxlen, vocab_size)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39m# inputs = Input(shape=(maxlen,))\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39m# embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, d_model)\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39m# x = embedding_layer(inputs)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    148\u001b[0m \n\u001b[0;32m    149\u001b[0m \u001b[39m######################## START ########################\u001b[39;00m\n\u001b[0;32m    150\u001b[0m inputs \u001b[39m=\u001b[39m Input(shape\u001b[39m=\u001b[39m(maxlen,))\n\u001b[1;32m--> 151\u001b[0m embedding_layer \u001b[39m=\u001b[39m TokenAndPositionEmbedding(maxlen, vocab_size, d_model)\n\u001b[0;32m    152\u001b[0m x \u001b[39m=\u001b[39m embedding_layer(inputs)\n\u001b[0;32m    153\u001b[0m transformer_block1 \u001b[39m=\u001b[39m TransformerBlock(d_model, \u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m)\n",
      "File \u001b[1;32md:\\lessons\\MSc\\3rd Term\\Evolutionary Computing\\Exercise\\Github repo\\Evolutionary-Computing\\HW3\\transformer_network_creator.py:78\u001b[0m, in \u001b[0;36mTokenAndPositionEmbedding.__init__\u001b[1;34m(self, maxlen, vocab_size, d_model)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, maxlen, vocab_size, d_model):\n\u001b[0;32m     77\u001b[0m     \u001b[39msuper\u001b[39m(TokenAndPositionEmbedding, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken_emb \u001b[39m=\u001b[39m Embedding(input_dim\u001b[39m=\u001b[39;49mvocab_size, output_dim\u001b[39m=\u001b[39;49md_model)\n\u001b[0;32m     79\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_emb \u001b[39m=\u001b[39m Embedding(input_dim\u001b[39m=\u001b[39mmaxlen, output_dim\u001b[39m=\u001b[39md_model)\n",
      "File \u001b[1;32mc:\\Users\\dadga\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\dtensor\\utils.py:96\u001b[0m, in \u001b[0;36mallow_initializer_layout.<locals>._wrap_function\u001b[1;34m(layer_instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[39mif\u001b[39;00m layout:\n\u001b[0;32m     94\u001b[0m             layout_args[variable_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_layout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m layout\n\u001b[1;32m---> 96\u001b[0m init_method(layer_instance, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     98\u001b[0m \u001b[39m# Inject the layout parameter after the invocation of __init__()\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39mfor\u001b[39;00m layout_param_name, layout \u001b[39min\u001b[39;00m layout_args\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\dadga\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\core\\embedding.py:131\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[1;34m(self, input_dim, output_dim, embeddings_initializer, embeddings_regularizer, activity_regularizer, embeddings_constraint, mask_zero, input_length, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m         kwargs[\u001b[39m\"\u001b[39m\u001b[39minput_shape\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (\u001b[39mNone\u001b[39;00m,)\n\u001b[1;32m--> 131\u001b[0m \u001b[39mif\u001b[39;00m input_dim \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m output_dim \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m:\n\u001b[0;32m    132\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    133\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mBoth `input_dim` and `output_dim` should be positive, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived input_dim = \u001b[39m\u001b[39m{\u001b[39;00minput_dim\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    135\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mand output_dim = \u001b[39m\u001b[39m{\u001b[39;00moutput_dim\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    136\u001b[0m     )\n\u001b[0;32m    137\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    138\u001b[0m     \u001b[39mnot\u001b[39;00m base_layer_utils\u001b[39m.\u001b[39mv2_dtype_behavior_enabled()\n\u001b[0;32m    139\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m kwargs\n\u001b[0;32m    140\u001b[0m ):\n\u001b[0;32m    141\u001b[0m     \u001b[39m# In TF1, the dtype defaults to the input dtype which is typically\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[39m# int32, so explicitly set it to floatx\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<=' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "from transformer_network_creator import start_training\n",
    "\n",
    "start_training(answer_chromosome)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c381ab827b2c72672c136fca7feabf28897bbc6ea06ab9a5379db0b1c88ea78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
